#!/usr/bin/env ruby

# Copyright (c) 2012-2014 Snowplow Analytics Ltd. All rights reserved.
#
# This program is licensed to you under the Apache License Version 2.0,
# and you may not use this file except in compliance with the Apache License Version 2.0.
# You may obtain a copy of the Apache License Version 2.0 at http://www.apache.org/licenses/LICENSE-2.0.
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the Apache License Version 2.0 is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the Apache License Version 2.0 for the specific language governing permissions and limitations there under.

# Author::    Alex Dean (mailto:support@snowplowanalytics.com)
# Copyright:: Copyright (c) 2012-2014 Snowplow Analytics Ltd
# License::   Apache License Version 2.0

# Don't edit $LOAD_PATH, go straight to main Ruby file
require File.expand_path(File.join(File.dirname(__FILE__), '..', 'lib', 'snowplow-emr-etl-runner'))

# Initialization
runner = Snowplow::EmrEtlRunner
fatal = runner::Logging.method(:fatal_with)

# This Ruby script runs the ETL (extract, transform, load)
# process which transforms the raw Snowplow event logs into
# Snowplow-formatted Hive data tables, optimised for analysis.
#
# This is a three-step process:
# 1. Transfer the raw Snowplow event logs from the In Bucket to the Processing Bucket
# 2. Run the Hive ETL process on the logs using Amazon EMR (populates processed Snowplow events into the Out Bucket)
# 3. Archive the processed event logs from Processing Bucket to Archive Bucket
#
# Note that each step is only actioned if the previous step succeeded without error.
begin

  args, config = runner::Cli.get_args_config()
  r = runner::Runner.new(args, config)
  r.run()

# Catch any Snowplow error
rescue runner::Error => e
  fatal.call(e)
  exit 1
rescue SystemExit => e
  exit 1
rescue Exception => e
  fatal.call(e)
  exit 1
end

exit 0 # Success
